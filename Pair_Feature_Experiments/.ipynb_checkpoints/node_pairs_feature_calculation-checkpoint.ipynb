{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground Truth\n",
    "\n",
    "First, calculate and save paired node features based on the ground-truth community classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load pandas dataframes of individual node metrics\n",
    "'''\n",
    "\n",
    "nodes = pd.read_csv('gt_node_features.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create dictionary of node pairs with metrics from both individual nodes\n",
    "'''\n",
    "metrics_list = [metric + '_A' for metric in list(nodes.columns)] + [metric + '_B' for metric in list(nodes.columns)]\n",
    "\n",
    "node_pair_metrics = {metric: {} for metric in metrics_list}\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                node_1_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node1)])\n",
    "                node_2_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node2)])\n",
    "                pair_values = np.concatenate([node_1_values, node_2_values])\n",
    "                pair_name = 'graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2)\n",
    "                for i, metric in enumerate(metrics_list):\n",
    "                    node_pair_metrics[metric][pair_name] = pair_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert the dictionary to our new node pairs dataframe\n",
    "'''\n",
    "\n",
    "node_pairs = pd.DataFrame(node_pair_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_path_deg_metrics(G, shortest_path, pair_name, new_metrics):\n",
    "    degrees_on_shortest_path = list(dict(G.degree(shortest_path)).values())\n",
    "    new_metrics['Mean Deg. on Path'][pair_name] = np.mean(degrees_on_shortest_path)\n",
    "    new_metrics['Median Deg. on Path'][pair_name] = np.median(degrees_on_shortest_path)\n",
    "    new_metrics['Max Deg. on Path'][pair_name] = np.max(degrees_on_shortest_path)\n",
    "    new_metrics['Min Deg. on Path'][pair_name] = np.min(degrees_on_shortest_path)\n",
    "    new_metrics['Var of Deg. on Path'][pair_name] = np.var(degrees_on_shortest_path)\n",
    "    return new_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate new metrics that relate to pairs of nodes\n",
    "'''\n",
    "\n",
    "new_metrics = {'Shortest Path Length': {}, 'Triadic Closure': {}, 'Mean Deg. on Path': {}, 'Median Deg. on Path': {}, \n",
    "              'Max Deg. on Path': {}, 'Min Deg. on Path': {}, 'Var of Deg. on Path': {}}\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        graph_yml = '../LFR_Graph_Data/mu_0_{0}/graph_0{1}/graph_0{1}_mu_0_{0}.yml'.format(mu, g_num)\n",
    "        with open(graph_yml) as f:\n",
    "            graph_info = yaml.load(f, Loader=yaml.Loader)\n",
    "        G = graph_info['G']\n",
    "        paths = nx.shortest_path(G)\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                pair_name = 'graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2)\n",
    "                shortest_path = paths[node1][node2]\n",
    "                path_len = len(shortest_path) - 1\n",
    "                new_metrics['Shortest Path Length'][pair_name] = path_len\n",
    "                if path_len == 1:\n",
    "                    new_metrics['Triadic Closure'][pair_name] = len(sorted(nx.common_neighbors(G, node1, node2)))\n",
    "                else:\n",
    "                    new_metrics['Triadic Closure'][pair_name] = 0\n",
    "                new_metrics = calc_path_deg_metrics(G, shortest_path, pair_name, new_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_metrics = pd.DataFrame(new_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine the individual metrics with the pair metrics\n",
    "'''\n",
    "\n",
    "node_pairs_df = pd.concat([node_pairs, pair_metrics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Temporarily save the whole dataframe as we do not yet have classification labels\n",
    "'''\n",
    "\n",
    "node_pairs_df.to_csv('node_pair_gt_x.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louvain \n",
    "\n",
    "We do not need to calculate new node metrics for any of the new algorithms, as we can just combine ones calculated during node feature experiments, with those calculated above. We only need to generate the new labels, and then save the X and y train/test CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load pandas dataframes of individual node metrics\n",
    "'''\n",
    "\n",
    "train_nodes = pd.read_csv('../LFR_Graph_Data/Louvain_Data/node_x_train.csv', index_col=0)\n",
    "test_nodes = pd.read_csv('../LFR_Graph_Data/Louvain_Data/node_x_test.csv', index_col=0)\n",
    "\n",
    "nodes = pd.concat([train_nodes, test_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create dictionary of node pairs with metrics from both individual nodes\n",
    "'''\n",
    "metrics_list = [metric + '_A' for metric in list(nodes.columns)] + [metric + '_B' for metric in list(nodes.columns)]\n",
    "\n",
    "node_pair_metrics = {metric: {} for metric in metrics_list}\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                node_1_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node1)])\n",
    "                node_2_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node2)])\n",
    "                pair_values = np.concatenate([node_1_values, node_2_values])\n",
    "                pair_name = 'graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2)\n",
    "                for i, metric in enumerate(metrics_list):\n",
    "                    node_pair_metrics[metric][pair_name] = pair_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert the dictionary to our new node pairs dataframe\n",
    "'''\n",
    "\n",
    "node_pairs = pd.DataFrame(node_pair_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine the individual metrics with the pair metrics\n",
    "'''\n",
    "\n",
    "X = pd.concat([node_pairs, pair_metrics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate the labels\n",
    "'''\n",
    "\n",
    "classification_values = []\n",
    "indices = []\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        C = '../LFR_Graph_Data/Community_Data/Louvain/Coassociation/graph_0{1}_mu_0_{0}_coassociation.npy'.format(mu, g_num)\n",
    "        C = np.load(C)\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                bin_val = 0\n",
    "                if C[node1, node2] > 0.5:\n",
    "                    bin_val = 1\n",
    "                classification_values.append(bin_val)\n",
    "                indices.append('graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2))\n",
    "                \n",
    "y = pd.DataFrame(classification_values, index=indices, columns=['Same Community'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split into test and train\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the CSV files\n",
    "'''\n",
    "\n",
    "X_train.to_csv('node_pair_louvain_x_train.csv')\n",
    "X_test.to_csv('node_pair_louvain_x_test.csv')\n",
    "y_train.to_csv('node_pair_louvain_y_train.csv')\n",
    "y_test.to_csv('node_pair_louvain_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load pandas dataframes of individual node metrics\n",
    "'''\n",
    "\n",
    "train_nodes = pd.read_csv('../LFR_Graph_Data/Infomap_Data/node_x_train.csv', index_col=0)\n",
    "test_nodes = pd.read_csv('../LFR_Graph_Data/Infomap_Data/node_x_test.csv', index_col=0)\n",
    "\n",
    "nodes = pd.concat([train_nodes, test_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create dictionary of node pairs with metrics from both individual nodes\n",
    "'''\n",
    "metrics_list = [metric + '_A' for metric in list(nodes.columns)] + [metric + '_B' for metric in list(nodes.columns)]\n",
    "\n",
    "node_pair_metrics = {metric: {} for metric in metrics_list}\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                node_1_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node1)])\n",
    "                node_2_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node2)])\n",
    "                pair_values = np.concatenate([node_1_values, node_2_values])\n",
    "                pair_name = 'graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2)\n",
    "                for i, metric in enumerate(metrics_list):\n",
    "                    node_pair_metrics[metric][pair_name] = pair_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert the dictionary to our new node pairs dataframe\n",
    "'''\n",
    "\n",
    "node_pairs = pd.DataFrame(node_pair_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine the individual metrics with the pair metrics\n",
    "'''\n",
    "\n",
    "X = pd.concat([node_pairs, pair_metrics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate the labels\n",
    "'''\n",
    "\n",
    "classification_values = []\n",
    "indices = []\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        C = '../LFR_Graph_Data/Community_Data/Infomap/Coassociation/graph_0{1}_mu_0_{0}_coassociation.npy'.format(mu, g_num)\n",
    "        C = np.load(C)\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                bin_val = 0\n",
    "                if C[node1, node2] > 0.5:\n",
    "                    bin_val = 1\n",
    "                classification_values.append(bin_val)\n",
    "                indices.append('graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2))\n",
    "                \n",
    "y = pd.DataFrame(classification_values, index=indices, columns=['Same Community'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split into test and train\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the CSV files\n",
    "'''\n",
    "\n",
    "X_train.to_csv('node_pair_infomap_x_train.csv')\n",
    "X_test.to_csv('node_pair_infomap_x_test.csv')\n",
    "y_train.to_csv('node_pair_infomap_y_train.csv')\n",
    "y_test.to_csv('node_pair_infomap_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Girvan-Newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load pandas dataframes of individual node metrics\n",
    "'''\n",
    "\n",
    "train_nodes = pd.read_csv('../LFR_Graph_Data/GN_Data/node_x_train.csv', index_col=0)\n",
    "test_nodes = pd.read_csv('../LFR_Graph_Data/GN_Data/node_x_test.csv', index_col=0)\n",
    "\n",
    "nodes = pd.concat([train_nodes, test_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create dictionary of node pairs with metrics from both individual nodes\n",
    "'''\n",
    "metrics_list = [metric + '_A' for metric in list(nodes.columns)] + [metric + '_B' for metric in list(nodes.columns)]\n",
    "\n",
    "node_pair_metrics = {metric: {} for metric in metrics_list}\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                node_1_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node1)])\n",
    "                node_2_values = np.array(nodes.loc['graph_{0}_{1}_node_{2}'.format(mu, g_num, node2)])\n",
    "                pair_values = np.concatenate([node_1_values, node_2_values])\n",
    "                pair_name = 'graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2)\n",
    "                for i, metric in enumerate(metrics_list):\n",
    "                    node_pair_metrics[metric][pair_name] = pair_values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert the dictionary to our new node pairs dataframe\n",
    "'''\n",
    "\n",
    "node_pairs = pd.DataFrame(node_pair_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combine the individual metrics with the pair metrics\n",
    "'''\n",
    "\n",
    "X = pd.concat([node_pairs, pair_metrics], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate the labels\n",
    "'''\n",
    "\n",
    "classification_values = []\n",
    "indices = []\n",
    "\n",
    "for mu in [1,2,3,4]:\n",
    "    for g_num in [1,2,3,4,5]:\n",
    "        C = '../LFR_Graph_Data/Community_Data/GN/Coassociation/graph_0{1}_mu_0_{0}_coassociation.npy'.format(mu, g_num)\n",
    "        C = np.load(C)\n",
    "        for node1 in range(200):\n",
    "            for node2 in range(node1 + 1, 200):\n",
    "                bin_val = 0\n",
    "                if C[node1, node2] > 0.5:\n",
    "                    bin_val = 1\n",
    "                classification_values.append(bin_val)\n",
    "                indices.append('graph_{0}_{1}_nodes_{2}_{3}'.format(mu, g_num, node1, node2))\n",
    "                \n",
    "y = pd.DataFrame(classification_values, index=indices, columns=['Same Community'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split into test and train\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the CSV files\n",
    "'''\n",
    "\n",
    "X_train.to_csv('node_pair_gn_x_train.csv')\n",
    "X_test.to_csv('node_pair_gn_x_test.csv')\n",
    "y_train.to_csv('node_pair_gn_y_train.csv')\n",
    "y_test.to_csv('node_pair_gn_y_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
