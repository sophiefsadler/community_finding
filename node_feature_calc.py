"""
Calculate the node features for every graph, given the coassociation matrix
produced by each of the algorithms.

The graphs_folder input must be a folder of the structure generated by
graph_gen.py.

The experiment_folder must contain a folder called Runs generated by partition_gen
and a folder called Coassociation generated by coassociation_gen.

Usage:
  node_feature_calc.py <graphs_folder> <experiment_folder>

Options:
  -h --help            Show this help message

"""

import os
import yaml
import math
import numpy as np
import pandas as pd
import networkx as nx
from scipy.stats import entropy

from docopt import docopt
from tqdm import tqdm


def calc_node_metrics(G):
    node_degrees = dict(G.degree())
    node_clustering_coefficients = nx.clustering(G)
    node_betweenness = nx.betweenness_centrality(G)
    node_closeness = nx.closeness_centrality(G)
    node_eigenvector = nx.eigenvector_centrality(G, max_iter=1000)
    node_av_shortest_paths = {}
    for i in range(G.number_of_nodes()):
        shortest_paths = nx.algorithms.shortest_paths.generic.shortest_path_length(G, source=i)
        if list(shortest_paths.values())[1:] != []:
            average_shortest_path = np.mean(list(shortest_paths.values())[1:])
        else:
            average_shortest_path = 0
        node_av_shortest_paths[i] = average_shortest_path
    node_metrics = {'Degree': node_degrees, 'Clustering Coefficient': node_clustering_coefficients, 'Betweenness': node_betweenness, 
                    'Closeness': node_closeness, 'Shortest Path': node_av_shortest_paths, 'Eigenvector': node_eigenvector}
    return node_metrics, node_degrees


def convert_parts_format(parts):
    final_parts_list = []
    for i in range(parts.shape[0]):
        current_part = parts[i, :]
        converted_part = [[] for _ in range(max(current_part))]
        for node, comm in enumerate(current_part):
            converted_part[comm - 1].append(node) # Subtract 1 since communities are indexed from 1
        final_parts_list.append(converted_part)
    return final_parts_list


def initialise_new_metrics(n_nodes):
    e_in_list = {i: [] for i in range(n_nodes)}
    e_out_list = {i: [] for i in range(n_nodes)}

    e_in_over_e_out = {i: [] for i in range(n_nodes)}
    odf = {i: [] for i in range(n_nodes)}

    expansion = {i: [] for i in range(n_nodes)}
    cut_ratio = {i: [] for i in range(n_nodes)}
    conductance = {i: [] for i in range(n_nodes)}
    normalised_cut = {i: [] for i in range(n_nodes)}

    triangle_participation = {i: [] for i in range(n_nodes)}
    
    new_metric_dict = {'E In': e_in_list, 'E Out': e_out_list, 'E In Over E Out': e_in_over_e_out,
                       'ODF': odf, 'Expansion': expansion, 'Cut Ratio': cut_ratio,
                       'Conductance': conductance, 'Normalised Cut': normalised_cut, 
                       'Triangle Participation': triangle_participation}
    return new_metric_dict


def calc_new_metrics(new_metrics, G, partitions, node_degrees):
    for part in tqdm(partitions):
        for comm in part:

            comm_subgraph = G.subgraph(comm)
            comm_degrees = comm_subgraph.degree()
            
            w = len(comm)
            N = G.number_of_nodes()
            m = G.number_of_edges()

            for nod in dict(comm_degrees).keys():
                e_in = comm_degrees[nod]
                e_out = node_degrees[nod] - e_in

                new_metrics['E In'][nod].append(e_in)
                new_metrics['E Out'][nod].append(e_out)

                # For e_in divided by e_out, if e_out is 0, just return the value of e_in
                try:
                    new_metrics['E In Over E Out'][nod].append(e_in/e_out)
                except ZeroDivisionError:
                    new_metrics['E In Over E Out'][nod].append(e_in)

                new_metrics['ODF'][nod].append(e_out/node_degrees[nod])

                new_metrics['Expansion'][nod].append(e_out/w)
                try:
                    new_metrics['Cut Ratio'][nod].append(e_out/(N-w))
                except ZeroDivisionError:
                    new_metrics['Cut Ratio'][nod].append(0)

                ct = e_out/(node_degrees[nod] + e_in)
                new_metrics['Conductance'][nod].append(ct)

                nc = ct + e_out/(2*m - 2*e_in + e_out)
                new_metrics['Normalised Cut'][nod].append(nc)

                tp = nx.triangles(comm_subgraph, nod)
                new_metrics['Triangle Participation'][nod].append(tp)
                
    return new_metrics


def average_metrics(new_metrics):
    averaged_metrics = new_metrics.copy()
    for met in averaged_metrics.keys():
        for nod in averaged_metrics[met].keys():
            averaged_metrics[met][nod] = np.mean(new_metrics[met][nod])
    return averaged_metrics


def new_node_metrics(node_metrics, partitions, node_degrees, n_nodes):
    new_metrics = initialise_new_metrics(n_nodes)
    new_metrics = calc_new_metrics(new_metrics, G, partitions, node_degrees)
    new_metrics = average_metrics(new_metrics)
    updated_node_metrics = node_metrics.copy()
    updated_node_metrics.update(new_metrics)
    return updated_node_metrics


def append_to_dataframe(X, node_metrics, n_nodes, graph_yml):
    df = pd.DataFrame(node_metrics)
    new_indices = [graph_yml.split('.')[0] + '_node_{0}'.format(k) for k in range(n_nodes)]
    df.index = new_indices
    X = pd.concat([X, df])
    return X


def element_entropy(C):
    E = np.empty_like(C)
    rows, cols = E.shape
    for row in range(rows):
        for col in range(cols):
            p = C[row,col]
            if p > 0:
                E[row,col] = -p * math.log(p, 2)
            else:
                E[row,col] = 0
    entrop = np.mean(E, axis=1)
    return entrop


if __name__ == '__main__':
    args = docopt(__doc__)
    graphs_folder = args.get('<graphs_folder>')
    experiment_folder = args.get('<experiment_folder>')

    if not os.path.exists(os.path.join(experiment_folder, 'Node_Features')):
        os.mkdir(os.path.join(experiment_folder, 'Node_Features'))

    if not os.path.exists(os.path.join(experiment_folder, 'Node_Entropies')):
        os.mkdir(os.path.join(experiment_folder, 'Node_Entropies'))

    for graph_loc in os.listdir(graphs_folder):

        graph_loc = os.path.join(graphs_folder, graph_loc)
        graph_contents = os.listdir(graph_loc)
        graph_yml = [x for x in graph_contents if x.endswith('yml')][0]
        with open(os.path.join(graph_loc, graph_yml)) as f:
            graph_info = yaml.load(f, Loader=yaml.Loader)
        G = graph_info['G']
        n_nodes = graph_info['n']

        features = pd.DataFrame()
        node_entropies = []

        graph_npy = graph_yml.split('.')[0] + '_runs.npy'
        parts_file = os.path.join(experiment_folder, 'Runs', graph_npy)
        parts = np.load(parts_file)

        coassociation_npy = graph_yml.split('.')[0] + '_coassociation.npy'
        coassociation_file = os.path.join(experiment_folder, 'Coassociation', coassociation_npy)
        C = np.load(coassociation_file)

        parts = convert_parts_format(parts)
        node_metrics, node_degrees = calc_node_metrics(G)
        node_metrics = new_node_metrics(node_metrics, parts, node_degrees, n_nodes)

        features = append_to_dataframe(features, node_metrics, n_nodes, graph_yml)
        features_path = os.path.join(experiment_folder, 'Node_Features', graph_yml.split('.')[0] + '_features.csv')
        features.to_csv(features_path)

        entropies = element_entropy(C)
        entropies = np.array(entropies)
        node_entropies = pd.DataFrame(entropies, index=features.index, columns=['Entropy'])
        entropies_path = os.path.join(experiment_folder, 'Node_Entropies', graph_yml.split('.')[0] + '_entropies.csv')
        node_entropies.to_csv(entropies_path)

