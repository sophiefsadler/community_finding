# community_finding

## Random Forest Feature Selection Experiments
You can find all the experiments that have been run so far in jupyter notebooks. There are 3 folders - Node_Feature_Experiments, Pair_Feature_Experiments, and Community_Feature_Experiments, splitting the code into experiments run on these 3 different levels.
### Node Feature Level
- **Classification Classes**: For the node feature level, the nodes were categorised into "stable" and "unstable". This was determined by their entropy. In the notebook entropy_plot you can see histograms of entropy across all nodes. The notebook cutoff_accuracy shows how the mean accuracy scores of the random forest varied depending on the cutoff value of entropy used to split nodes into "stable" and "unstable". Both notebooks are based on the data from runs of the Louvain algorithm.
- **Initial Louvain Experiments**: In notebook 1, feature selection is done only on data from runs of the louvain algorithm. The random forest is first trained using a stratified k-fold cross-validation, then subsequently also trained and validated on pairs of graphs. The latter method caused problems due to extremely unbalanced classification classes, so after this, only the former was used.
- **Further algorithms**: In notebook 2, feature selection is done on data from runs of different algorithms, using only the stratified k-fold cross-validation method.
- **Repeat Experiments**: In notebook 3, the experiments on different algorithms are repeated many times. Firstly, just by resetting the random forest; secondly by generating new runs of the algorithm and recalculating the node features; and finally by generating completely new LFR graphs and running the algorithms on the new data.
### Pair Feature Level
- **Initial Experiment**: The node-pair-level features are described and calculated in the node_pair_feature_calculation notebook.
- **Classification Classes**: For the node-pair feature level, pairs are categorised into "same community" or "different community". Unlike with the node feature level, this allows us to conduct an experiment using ground truth. As well as the ground truth experiment, we can classify pairs according to their communities in runs of the community finding algorithm. For this purpose, they are classified as "same community" if they are sorted into the same community in more than (or = to) 50% of the runs, and "different community" if they are sorted into the same community in less than 50% of the runs.
- **Ground Truth Experiment**: In notebook 1, the pair features are ranked according to their importance in classifying pairs as "same" or "different" communities in the ground truth.
- **Algorithm Experiments**: In notebook 2, the classification task marks pairs as "same community" if the algorithms classified them as the same community MORE than half of the time, and "different community" if LESS than half of the time.

## Data
- **Graph Generation**: The python file `graph_gen.py` was used to generate the 20 LFR graphs.
- **Graph Folders**: In each of the mu folders within the `LFR_Graph_Data` directory, there are 5 graph subfolders, which each contain files with information on 1 graph. There is a raw COMMS and EDGES file for each graph, containing the edge information and the ground truth communities. There is also a yaml file which contains a NetworkX version of the graph, the communities, the parameters used to create the graph (including random seed) and the coordinates used to plot the graph in the png file, which displays an image of the graph.
- **Node Level Features**: 
    - There is a subfolder in `LFR_Graph_Data` for each community finding algorithm. Within these, there are 4 CSV files. The 2 x files contain a list of nodes with all the calculated node features. These should be read into pandas dataframes using the `index_col` parameter; for example: `x_train = pd.read_csv('node_x_train.csv', index_col=0)` to ensure that the first column is recognised as the node names rather than an additional feature. The y files contain a list of nodes with a single value determining whether they are classified as "stable" or "unstable", and should be read into pandas dataframes using `index_col` in the same way. Both x and y are split into test and train sets - the train sets have been used for training and validation in the experiments described above, and the test sets have not been touched at all. The split is stratified so that there is the same proportion of "stable" and "unstable" nodes in the train and test sets.
    - The data was generated using the python files in the root folder. First, many runs of the algorithm are generated by running `python partition_gen.py louvain` (for example). Then the coassociation matrices are generated from these runs using `python coassociation_gen.py louvain`, and finally, node features are calculated using `python node_feature_calc.py louvain`. The runs and coassociation matrices are stored in `LFR_Graph_Data/Community_Data/[algorithm]/Runs` and `LFR_Graph_Data/Community_Data/[algorithm]/Coassociation` respectively, before the final CSV files are generated and stored as described above.
    - Inside `LFR_Graph_Data` there is a folder called `Repeat_Data` containing many repeats of the above. At the root, there is also a folder called `Repeat_Graph_Data` containing the different sets of graphs used in repeat experiments, and the runs/coassociation matrices/final CSV files for these.
- **Node Pair Level Features**: In `Pair_Feature_Experiments/[algorithm]_Data` the final CSV files used for training the random forests can be found, although these contain only a subset of the training set. The full set is too large to store in a CSV file on GitHub.

## Examples
The notebook community_finding.ipynb shows an example of running the louvain community finding algorithm and visualizing a graph with or without communities labelled.
